# ============================================================
# Multi-Agent Research Lab (HF Inference / DuckDuckGo / Orquestaci√≥n)
# ============================================================

import os
from dotenv import load_dotenv
from huggingface_hub import InferenceClient
from langchain_community.utilities import DuckDuckGoSearchAPIWrapper


# ==========================
# Cargar token HF desde .env
# ==========================

load_dotenv()

def leer_token():
    token = os.getenv("HF_TOKEN")
    if token is None:
        raise ValueError(
            "‚ùå ERROR: No se encontr√≥ HF_TOKEN en .env.\n"
            "Crea un archivo .env con:\nHF_TOKEN=tu_token_aqui"
        )
    return token


# ======================================================
# 1. AGENTE INVESTIGADOR
# ======================================================

class Investigador:
    """
    Realiza b√∫squedas web usando DuckDuckGo.
    """
    def __init__(self, top_k=5):
        self.search = DuckDuckGoSearchAPIWrapper()  # API funcional
        self.top_k = top_k

    def buscar(self, query):
        try:
            resultados = self.search.results(query, max_results=self.top_k)
            textos = []

            for r in resultados:
                titulo = r.get("title", "")
                snippet = r.get("body", "")
                textos.append(f"üìå {titulo}\n{snippet}\n")

            return "\n".join(textos)

        except Exception as e:
            return f"Error en b√∫squeda: {e}"


# ======================================================
# 2. AGENTE REDACTOR ‚Äî Modelo HF via text_generation
# ======================================================

class Redactor:
    """
    Genera texto usando InferenceClient (HF).
    """
    def __init__(self, modelo="meta-llama/Llama-3.1-8B-Instruct"):
        self.modelo = modelo
        self.client = InferenceClient(token=leer_token())

    def generar_resumen(self, texto):
        """
        Genera un resumen o narrativa usando text_generation() actualizado.
        """
        try:
            respuesta = self.client.text_generation(
                model=self.modelo,
                prompt=(
                    "Eres un investigador acad√©mico. "
                    "Resume los siguientes hallazgos en un estilo claro, conciso y profesional:\n\n"
                    f"{texto}\n\nResumen:"
                ),
                max_new_tokens=450,
                temperature=0.5,
            )

            return respuesta

        except Exception as e:
            return f"Error en generaci√≥n: {e}"


# ======================================================
# 3. AGENTE REVISOR ‚Äî Simula revisi√≥n acad√©mica
# ======================================================

class Revisor:
    """
    Genera retroalimentaci√≥n del texto.
    """
    def __init__(self):
        pass

    def evaluar_texto(self, texto):
        evaluacion = (
            "‚Ä¢ El resumen presenta coherencia general y sigue una estructura clara.\n"
            "‚Ä¢ Se sugiere fortalecer el tono acad√©mico usando transiciones formales.\n"
            "‚Ä¢ Podr√≠as incluir ejemplos concretos para ilustrar puntos clave.\n"
            "‚Ä¢ Incluye limitaciones o vac√≠os en la literatura para mayor solidez.\n"
        )
        return evaluacion


# ======================================================
# 4. COORDINADOR ‚Äî Orquesta el flujo
# ======================================================

class Coordinator:
    def __init__(self, investigador, redactor, revisor):
        self.investigador = investigador
        self.redactor = redactor
        self.revisor = revisor

    def run(self, tema, top_k=5):
        # 1) B√öSQUEDA
        fuentes = self.investigador.buscar(tema)

        # 2) BORRADOR
        draft = self.redactor.generar_resumen(fuentes)

        # 3) REVISI√ìN
        review = self.revisor.evaluar_texto(draft)

        # 4) FINAL
        final = (
            f"{draft}\n\n"
            "### Ajustes propuestos por el revisor:\n"
            f"{review}\n"
        )

        return {
            "sources": fuentes,
            "draft": draft,
            "review": review,
            "final": final
        }
